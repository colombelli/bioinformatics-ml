{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f50e29fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import kendalltau, spearmanr, rankdata\n",
    "from scipy.spatial.distance import canberra\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eb5027a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_files = {\n",
    "    \"ReliefF\": \"rf.csv\",\n",
    "    \"GeoDE\": \"gd.csv\",\n",
    "    \"GR\": \"gr.csv\",\n",
    "    \"SU\": \"su.csv\",\n",
    "    \"Wx\": \"wx.csv\"\n",
    "}\n",
    "\n",
    "\n",
    "def get_similarity_corr(path, correlation_function):\n",
    "    ranks = {}\n",
    "    corr_df = {}\n",
    "    p_value_df = {}\n",
    "    idx_ref = pd.read_csv(path+\"gd.csv\", index_col=0).index\n",
    "    \n",
    "    for key, value in ranks_files.items():\n",
    "        corr_df[key] = []\n",
    "        p_value_df[key] = []\n",
    "        ranks[key] = rankdata(pd.read_csv(path+value, index_col=0).loc[idx_ref, 'rank'])\n",
    "        \n",
    "    for key in corr_df.keys():\n",
    "        for key_pair, rank_pair in ranks.items():\n",
    "            c, p = correlation_function(ranks[key], rank_pair)\n",
    "            corr_df[key].append(c)\n",
    "            p_value_df[key].append(p)\n",
    "       \n",
    "    cdf = pd.DataFrame(corr_df)\n",
    "    pdf = pd.DataFrame(p_value_df)\n",
    "    cdf.index = list(ranks.keys())\n",
    "    pdf.index = list(ranks.keys())\n",
    "    \n",
    "    return cdf, pdf\n",
    "\n",
    "\n",
    "def get_cd_similarity_corr(path, correlation_function):\n",
    "    ranks = {}\n",
    "    df = {}\n",
    "    idx_ref = pd.read_csv(path+\"gd.csv\", index_col=0).index\n",
    "    \n",
    "    for key, value in ranks_files.items():\n",
    "        df[key] = []\n",
    "        ranks[key] = rankdata(pd.read_csv(path+value, index_col=0).loc[idx_ref, 'rank'])\n",
    "        \n",
    "    for key in df.keys():\n",
    "        for key_pair, rank_pair in ranks.items():\n",
    "            try:\n",
    "                c, p = correlation_function(ranks[key], rank_pair)\n",
    "                df[key].append((c,p))\n",
    "            except:\n",
    "                metric = correlation_function(ranks[key], rank_pair)\n",
    "                df[key].append(metric)\n",
    "       \n",
    "    dataframe = pd.DataFrame(df)\n",
    "    dataframe.index = list(ranks.keys())\n",
    "    return dataframe\n",
    "\n",
    "    \n",
    "def get_matrixes(read_from, correlation_function):\n",
    "    bs_paths = [read_from+\"bootstrap_\"+str(i)+\"/\" for i in range(1,51)]\n",
    "    matrixes_c = []\n",
    "    matrixes_p = []\n",
    "    for path in bs_paths:\n",
    "        cdf, pdf = get_similarity_corr(path, correlation_function)\n",
    "        matrixes_c.append(cdf)\n",
    "        matrixes_p.append(pdf)\n",
    "        \n",
    "    return matrixes_c, matrixes_p\n",
    "\n",
    "\n",
    "def get_dp_matrixes(read_from, correlation_function):\n",
    "    bs_paths = [read_from+\"bootstrap_\"+str(i)+\"/\" for i in range(1,51)]\n",
    "    matrixes = []\n",
    "    for path in bs_paths:\n",
    "        matrixes.append(get_cd_similarity_corr(path, correlation_function))\n",
    "        \n",
    "    return matrixes\n",
    "\n",
    "\n",
    "def get_canberra_matrixes(read_from):\n",
    "    bs_paths = [read_from+\"bootstrap_\"+str(i)+\"/\" for i in range(1,51)]\n",
    "    matrixes = []\n",
    "    for path in bs_paths:\n",
    "        matrixes.append(get_cd_similarity_corr(path, canberra))\n",
    "        \n",
    "    return matrixes\n",
    "    \n",
    "\n",
    "def save_matrixes(saving_path, matrixes1, matrixes2=None, sufix=\"f1_bs\"):\n",
    "    tuple_matrixes=True\n",
    "    if matrixes2 != None:\n",
    "        tuple_matrixes=False\n",
    "        os.mkdir(saving_path+\"double_matrixes\")\n",
    "        path = saving_path+\"double_matrixes/\"\n",
    "    else: \n",
    "        os.mkdir(saving_path+\"tuple_matrixes\")\n",
    "        path = saving_path+\"tuple_matrixes/\"\n",
    "\n",
    "    if tuple_matrixes:\n",
    "        for i, m in enumerate(tqdm(matrixes1)):\n",
    "            m.to_csv(path+sufix+\"bs_\"+str(i+1)+\".csv\")\n",
    "        \n",
    "        #mean_matrix = pd.concat(matrixes1).groupby(level=0).mean()\n",
    "        #mean_matrix.to_csv(path+mean)\n",
    "        \n",
    "    else:\n",
    "        for i, m in enumerate(tqdm(matrixes1)):\n",
    "            m.to_csv(path+\"corr_\"+sufix+str(i+1)+\".csv\")\n",
    "            matrixes2[i].to_csv(path+\"pval_\"+sufix+str(i+1)+\".csv\")\n",
    "        \n",
    "        path+=\"mean/\"\n",
    "        os.mkdir(path)\n",
    "        mean_matrix1 = pd.concat(matrixes1).groupby(level=0).mean().loc[list(ranks_files.keys()), :]\n",
    "        mean_matrix1.to_csv(path+\"mean_corr_\"+sufix[:-3]+\".csv\")\n",
    "        mean_matrix2 = pd.concat(matrixes2).groupby(level=0).mean().loc[list(ranks_files.keys()), :]\n",
    "        mean_matrix2.to_csv(path+\"mean_pval_\"+sufix[:-3]+\".csv\")\n",
    "    return\n",
    "\n",
    "\n",
    "def save_matrixes_canberra(path, matrixes, sufix=\"f1_bs\"): \n",
    "    for i, m in enumerate(tqdm(matrixes)):\n",
    "        m.to_csv(path+sufix+\"bs_\"+str(i+1)+\".csv\")\n",
    "\n",
    "    path+=\"mean/\"\n",
    "    os.mkdir(path)\n",
    "    mean_matrix = pd.concat(matrixes).groupby(level=0).mean().loc[list(ranks_files.keys()), :]\n",
    "    mean_matrix.to_csv(path+\"mean.csv\")\n",
    "    return\n",
    "        \n",
    "\n",
    "def execute_all(read_from, save_to, correlation_function, fold=1):\n",
    "    path=read_from+\"fold_\"+str(fold)+\"/\"\n",
    "    print(\"Executing for double matrixes...\")\n",
    "    corr, pval = get_matrixes(path, correlation_function)\n",
    "    save_matrixes(save_to, corr, pval, sufix=\"f\"+str(fold)+\"_bs\")\n",
    "    \n",
    "    print(\"\\nExecuting for tuple matrixes...\")\n",
    "    matrixes = get_dp_matrixes(path, correlation_function)\n",
    "    save_matrixes(save_to, matrixes, sufix=\"f\"+str(fold)+\"_bs\")\n",
    "    return\n",
    "\n",
    "def execute_all_canberr(read_from, save_to, fold=1):\n",
    "    path=read_from+\"fold_\"+str(fold)+\"/\"\n",
    "    print(\"Executing for canberra matrixes...\")\n",
    "    matrixes = get_canberra_matrixes(path)\n",
    "    save_matrixes_canberra(save_to, matrixes, sufix=\"f\"+str(fold)+\"_bs\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "400047ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating similarities with Spearman Rank Correlation...\n",
      "Executing for double matrixes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 527.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing for tuple matrixes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 959.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Calculating similarities with Kendall Tau Rank Correlation...\n",
      "Executing for double matrixes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 316.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Executing for tuple matrixes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 757.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Calculating similarities with Canberra distance...\n",
      "Executing for canberra matrixes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 1309.10it/s]\n"
     ]
    }
   ],
   "source": [
    "read_from = \"/home/colombelli/Documents/pmlb_efs_experiments/results/hyb_sonar_E3/\"\n",
    "\n",
    "print(\"Calculating similarities with Spearman Rank Correlation...\")\n",
    "save_to = \"/home/colombelli/Documents/pmlb_efs_experiments/similarities/sonar_spearman/\"\n",
    "execute_all(read_from, save_to, spearmanr, fold=1)\n",
    "\n",
    "print(\"\\n\\nCalculating similarities with Kendall Tau Rank Correlation...\")\n",
    "save_to = \"/home/colombelli/Documents/pmlb_efs_experiments/similarities/sonar_kendalltau/\"\n",
    "execute_all(read_from, save_to, kendalltau, fold=1)\n",
    "\n",
    "\n",
    "print(\"\\n\\nCalculating similarities with Canberra distance...\")\n",
    "save_to = \"/home/colombelli/Documents/pmlb_efs_experiments/similarities/sonar_canberra/\"\n",
    "execute_all_canberr(read_from, save_to, fold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5defc2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
